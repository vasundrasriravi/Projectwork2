## AccessWave : Gesture-Driven and Voice-Enabled Assistive Interaction System
The AccessWave project focuses on developing a gesture and voice-controlled system that enables users to interact with computers in a natural and touch-free manner. By integrating hand gesture recognition and voice command processing, the system simplifies computer operations and enhances user accessibility and experience.

## About
AccessWave is a gesture and voice-controlled system that enables touch-free interaction with computers.
It uses computer vision and speech recognition to understand hand gestures and voice commands.
The system improves accessibility and provides a natural, user-friendly way to control digital devices.
AccessWave is useful in assistive technology, smart environments, and modern human–computer interaction..

## Features
<!--List the features of the project as shown below-->
- Enables gesture-based control using real-time hand tracking and computer vision.
- Supports voice commands for hands-free interaction with the system.
- Provides touch-free human–computer interaction, improving accessibility and usability.
- Ensures real-time processing with fast response and low latency.
- Offers a user-friendly and flexible interface for seamless interaction.
- Can be integrated into assistive technologies and smart environments for enhanced control.

## Requirements
<!--List the requirements of the project as shown below-->
- Operating System: Requires Windows 10/11 or Linux (64‑bit) for running the gesture and voice recognition system.
- Programming Language: Python 3.7 or later for implementing gesture recognition and voice processing modules.
- Libraries & Frameworks: OpenCV for computer vision, SpeechRecognition and Pyttsx3 for voice interaction, and NumPy for data processing.
- Hardware Requirements: Webcam for gesture detection and microphone for voice input.
- Development Environment: IDE such as VS Code or PyCharm for coding and debugging the application.
- Additional Tools: Machine learning and AI libraries for real-time gesture recognition and system automation.



## System Architecture
<!--Embed the system architecture diagram as shown below-->
<img width="977" height="652" alt="image" src="https://github.com/user-attachments/assets/19c908b2-b246-4173-893b-a4353da55f73" />



## Output

<!--Embed the Output picture at respective places as shown below as shown below-->
#### Output1 - RIGHT CLICK


<img width="573" height="600" alt="image" src="https://github.com/user-attachments/assets/e4256783-30e2-4512-81a9-edfb15d6520d" />



#### Output2 - DOUBLE CLICK


<img width="573" height="600" alt="image" src="https://github.com/user-attachments/assets/f05ecfe6-65e2-480f-a81b-423efbea6a04" />


### OUTPUT 3 - VOICE ASSISANT
## HOME PAGE
<img width="573" height="675" alt="image" src="https://github.com/user-attachments/assets/646af5b5-ca8d-404e-bc6c-6687e14f4aa1" />


## SEARCHING
<img width="1067" height="580" alt="image" src="https://github.com/user-attachments/assets/904e01b5-04fd-4fd8-b0ba-128443f657f2" />

## Results
The AccessWave system successfully enables gesture and voice-based control of computer operations.
It accurately recognizes hand gestures and voice commands with low response time.
The system improves user interaction by providing a touch-free and intuitive interface.
Overall, the project demonstrates an efficient and accessible human–computer interaction solution.



## Articles published / References
```
1.T. Starner and A. Pentland, “Real-Time American Sign Language Recognition from Video Using Hidden Markov Models,” Proc. IEEE Int. Symp. Computer Vision, pp. 265–270, 1995.
2.R. Bowden, D. Windridge, T. Kadir, A. Zisserman, and M. Brady, “A Linguistic Feature Vector for the Visual Interpretation of Sign Language,” Proc. European Conf. Computer Vision (ECCV), pp. 390–401, 2004.
3.S. Mitra and T. Acharya, “Gesture Recognition: A Survey,” IEEE Trans. Systems, Man, and Cybernetics, Part C, vol. 37, no. 3, pp. 311–324, 2007.
```
